{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Notebook demonstrates how to reduce the bias during \"In-processing\" stage using AI 360 Fairness toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-processing algorithm\n",
    "A bias mitigation algorithm that is applied to a model during its training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert your credentials as credentials in the below cell\n",
    "Click on dropdown from Pipeline_LabelEncoder-0.1.zip under Data tab and select 'Credentials'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "# The following code contains the credentials for a file in your IBM Cloud Object Storage.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "credentials = {\n",
    "\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "cos = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id=credentials['IBM_API_KEY_ID'],\n",
    "    ibm_service_instance_id=credentials['IAM_SERVICE_ID'],\n",
    "    ibm_auth_endpoint=credentials['IBM_AUTH_ENDPOINT'],\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url=credentials['ENDPOINT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wsuser/work'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos.download_file(Bucket=credentials['BUCKET'],Key='Pipeline_LabelEncoder-0.1.zip',Filename='/home/wsuser/work/Pipeline_LabelEncoder-0.1.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline_LabelEncoder-0.1.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./Pipeline_LabelEncoder-0.1.zip\n",
      "Building wheels for collected packages: Pipeline-LabelEncoder\n",
      "  Building wheel for Pipeline-LabelEncoder (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for Pipeline-LabelEncoder: filename=Pipeline_LabelEncoder-0.1-py3-none-any.whl size=2062 sha256=29a5267412bb13a9c3feef0f41ecb000eba58891b4ed7ebb568ef7fda7b85bfb\n",
      "  Stored in directory: /tmp/wsuser/.cache/pip/wheels/6b/4b/1e/43f3c8b97ffade4539a329b9eaa5755e4df16a248960947534\n",
      "Successfully built Pipeline-LabelEncoder\n",
      "Installing collected packages: Pipeline-LabelEncoder\n",
      "  Attempting uninstall: Pipeline-LabelEncoder\n",
      "    Found existing installation: Pipeline-LabelEncoder 0.1\n",
      "    Uninstalling Pipeline-LabelEncoder-0.1:\n",
      "      Successfully uninstalled Pipeline-LabelEncoder-0.1\n",
      "Successfully installed Pipeline-LabelEncoder-0.1\n",
      "Requirement already satisfied: aif360 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (0.4.0)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from aif360) (1.2.4)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from aif360) (3.3.4)\n",
      "Requirement already satisfied: tempeh in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from aif360) (0.1.12)\n",
      "Requirement already satisfied: numpy>=1.16 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from aif360) (1.19.2)\n",
      "Requirement already satisfied: scikit-learn>=0.22.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from aif360) (0.23.2)\n",
      "Requirement already satisfied: scipy<1.6.0,>=1.2.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from aif360) (1.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pandas>=0.24.0->aif360) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pandas>=0.24.0->aif360) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->aif360) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from scikit-learn>=0.22.1->aif360) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from scikit-learn>=0.22.1->aif360) (0.17.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from matplotlib->aif360) (8.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from matplotlib->aif360) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from matplotlib->aif360) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from matplotlib->aif360) (2.4.7)\n",
      "Requirement already satisfied: shap in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tempeh->aif360) (0.40.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tempeh->aif360) (2.25.1)\n",
      "Requirement already satisfied: pytest in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tempeh->aif360) (6.2.3)\n",
      "Requirement already satisfied: memory-profiler in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tempeh->aif360) (0.58.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from memory-profiler->tempeh->aif360) (5.8.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pytest->tempeh->aif360) (21.2.0)\n",
      "Requirement already satisfied: iniconfig in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pytest->tempeh->aif360) (1.1.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pytest->tempeh->aif360) (21.3)\n",
      "Requirement already satisfied: pluggy<1.0.0a1,>=0.12 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pytest->tempeh->aif360) (0.13.1)\n",
      "Requirement already satisfied: py>=1.8.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pytest->tempeh->aif360) (1.10.0)\n",
      "Requirement already satisfied: toml in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pytest->tempeh->aif360) (0.10.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests->tempeh->aif360) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests->tempeh->aif360) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests->tempeh->aif360) (2021.10.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests->tempeh->aif360) (3.0.4)\n",
      "Requirement already satisfied: numba in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from shap->tempeh->aif360) (0.54.1)\n",
      "Requirement already satisfied: tqdm>4.25.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from shap->tempeh->aif360) (4.59.0)\n",
      "Requirement already satisfied: slicer==0.0.7 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from shap->tempeh->aif360) (0.0.7)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from shap->tempeh->aif360) (1.6.0)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from numba->shap->tempeh->aif360) (0.37.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from numba->shap->tempeh->aif360) (52.0.0.post20211006)\n"
     ]
    }
   ],
   "source": [
    "!pip install Pipeline_LabelEncoder-0.1.zip\n",
    "!pip install aif360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.3'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow>=2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (2.4.3)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=2) (1.1.2)\n",
      "Requirement already satisfied: six~=1.15.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=2) (1.15.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=2) (1.1.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=2) (2.4.1)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=2) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=2) (3.7.4.3)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=2) (1.6.3)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=2) (1.19.2)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=2) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=2) (2.4.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=2) (3.11.2)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=2) (0.2.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=2) (0.3.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=2) (1.12)\n",
      "Requirement already satisfied: absl-py~=0.10 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=2) (0.10.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=2) (1.32.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=2) (0.35.1)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=2) (1.12.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from protobuf>=3.9.2->tensorflow>=2) (52.0.0.post20211006)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow>=2) (0.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow>=2) (2.25.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow>=2) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow>=2) (2.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow>=2) (1.6.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow>=2) (1.23.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install 'tensorflow>=2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Load all necessary packages\n",
    "import pandas as pd\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert the data as Pandas Dataframe and change the name from df_data_ to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Education</th>\n",
       "      <th>Fraud_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>Risk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender Married  Education Fraud_risk\n",
       "0   Male      No          1       Risk\n",
       "1   Male     Yes          1       Safe\n",
       "2   Male     Yes          1       Safe\n",
       "3   Male     Yes          0       Safe\n",
       "4   Male      No          1       Risk"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os, types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "\n",
    "if os.environ.get('RUNTIME_ENV_LOCATION_TYPE') == 'external':\n",
    "    endpoint_abe73f625ce04410993f962955e934a8 = 'https://s3.us.cloud-object-storage.appdomain.cloud'\n",
    "else:\n",
    "    endpoint_abe73f625ce04410993f962955e934a8 = 'https://s3.private.us.cloud-object-storage.appdomain.cloud'\n",
    "\n",
    "client_abe73f625ce04410993f962955e934a8 = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='',\n",
    "    ibm_auth_endpoint=\"\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url=endpoint_abe73f625ce04410993f962955e934a8)\n",
    "\n",
    "body = client_abe73f625ce04410993f962955e934a8.get_object(Bucket='wwcdemo-donotdelete-pr-t7c1vptc0iudk2',Key='fraud_data.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "df = pd.read_csv(body)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Education</th>\n",
       "      <th>Fraud_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "      <td>921.000000</td>\n",
       "      <td>921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>703</td>\n",
       "      <td>501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730727</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.443823</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Gender Married   Education Fraud_risk\n",
       "count     921     921  921.000000        921\n",
       "unique      2       2         NaN          2\n",
       "top      Male      No         NaN       Safe\n",
       "freq      703     501         NaN        562\n",
       "mean      NaN     NaN    0.730727        NaN\n",
       "std       NaN     NaN    0.443823        NaN\n",
       "min       NaN     NaN    0.000000        NaN\n",
       "25%       NaN     NaN    0.000000        NaN\n",
       "50%       NaN     NaN    1.000000        NaN\n",
       "75%       NaN     NaN    1.000000        NaN\n",
       "max       NaN     NaN    1.000000        NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{'Gender': 1}]\n",
    "unprivileged_groups = [{'Gender': 0}]\n",
    "favorable_label = 1 \n",
    "unfavorable_label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Gender\n",
      "mapping {'Female': 0, 'Male': 1}\n",
      "Feature Married\n",
      "mapping {'No': 0, 'Yes': 1}\n",
      "Feature Fraud_risk\n",
      "mapping {'Risk': 0, 'Safe': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Education</th>\n",
       "      <th>Fraud_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Married  Education  Fraud_risk\n",
       "0       1        0          1           0\n",
       "1       1        1          1           1\n",
       "2       1        1          1           1\n",
       "3       1        1          0           1\n",
       "4       1        0          1           0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "categorical_column = ['Gender', 'Married', 'Fraud_risk']\n",
    "\n",
    "data_encoded = df.copy(deep=True)\n",
    "#Use Scikit-learn label encoding to encode character data\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "for col in categorical_column:\n",
    "        data_encoded[col] = lab_enc.fit_transform(df[col])\n",
    "        le_name_mapping = dict(zip(lab_enc.classes_, lab_enc.transform(lab_enc.classes_)))\n",
    "        print('Feature', col)\n",
    "        print('mapping', le_name_mapping)\n",
    "        \n",
    "\n",
    "data_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside fit transform\n",
      "Feature Gender\n",
      "mapping {0: 0, 1: 1}\n",
      "Feature Married\n",
      "mapping {0: 0, 1: 1}\n",
      "Feature Fraud_risk\n",
      "mapping {0: 0, 1: 1}\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "from Pipeline_LabelEncoder.sklearn_label_encoder import PipelineLabelEncoder\n",
    "preprocessed_data = PipelineLabelEncoder(columns = ['Gender','Married', 'Fraud_risk']).fit_transform(data_encoded)\n",
    "print('-------------------------')\n",
    "#print('validation data encoding')\n",
    "#validation_enc_data = PipelineLabelEncoder(columns = ['Gender','Married', 'Fraud_risk']).transform(validation_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create binary label dataset that can be used by bias mitigation algorithms\n",
    "fraud_dataset = BinaryLabelDataset(favorable_label=favorable_label,\n",
    "                                unfavorable_label=unfavorable_label,\n",
    "                                df=preprocessed_data,\n",
    "                                label_names=['Fraud_risk'],\n",
    "                                protected_attribute_names=['Gender', 'Married'],\n",
    "                                unprivileged_protected_attributes=unprivileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Training Data Details"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the training dataset (921, 3)\n",
      "Training data favorable label 1.0\n",
      "Training data unfavorable label 0.0\n",
      "Training data protected attribute ['Gender', 'Married']\n",
      "Training data privileged protected attribute (1:Male and 0:Female) [array([1.]), array([1.])]\n",
      "Training data unprivileged protected attribute (1:Male and 0:Female) [array([0.]), array([0.])]\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"#### Training Data Details\"))\n",
    "print(\"shape of the training dataset\", fraud_dataset.features.shape)\n",
    "print(\"Training data favorable label\", fraud_dataset.favorable_label)\n",
    "print(\"Training data unfavorable label\", fraud_dataset.unfavorable_label)\n",
    "print(\"Training data protected attribute\", fraud_dataset.protected_attribute_names)\n",
    "print(\"Training data privileged protected attribute (1:Male and 0:Female)\", \n",
    "      fraud_dataset.privileged_protected_attributes)\n",
    "print(\"Training data unprivileged protected attribute (1:Male and 0:Female)\",\n",
    "      fraud_dataset.unprivileged_protected_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_dataset_train, fraud_dataset_test = fraud_dataset.split([0.9], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.356787\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.487059\n"
     ]
    }
   ],
   "source": [
    "# Metric for the original dataset\n",
    "metric_orig_train = BinaryLabelDatasetMetric(fraud_dataset_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "metric_orig_test = BinaryLabelDatasetMetric(fraud_dataset_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_test.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Scaled dataset - Verify that the scaling does not affect the group label statistics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.356787\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.487059\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = MaxAbsScaler()\n",
    "fraud_dataset_train.features = min_max_scaler.fit_transform(fraud_dataset_train.features)\n",
    "fraud_dataset_test.features = min_max_scaler.transform(fraud_dataset_test.features)\n",
    "metric_scaled_train = BinaryLabelDatasetMetric(fraud_dataset_train, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Scaled dataset - Verify that the scaling does not affect the group label statistics\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_train.mean_difference())\n",
    "metric_scaled_test = BinaryLabelDatasetMetric(fraud_dataset_test, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_test.mean_difference())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build plan classifier without debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load post-processing algorithm that equalizes the odds\n",
    "# Learn parameters with debias set to False\n",
    "# sess = tf.Session()\n",
    "sess = tf.compat.v1.Session()\n",
    "plain_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='plain_classifier',\n",
    "                          debias=False,\n",
    "                          sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696636\n",
      "epoch 1; iter: 0; batch classifier loss: 0.645679\n",
      "epoch 2; iter: 0; batch classifier loss: 0.609091\n",
      "epoch 3; iter: 0; batch classifier loss: 0.609546\n",
      "epoch 4; iter: 0; batch classifier loss: 0.544035\n",
      "epoch 5; iter: 0; batch classifier loss: 0.555662\n",
      "epoch 6; iter: 0; batch classifier loss: 0.507495\n",
      "epoch 7; iter: 0; batch classifier loss: 0.528085\n",
      "epoch 8; iter: 0; batch classifier loss: 0.512081\n",
      "epoch 9; iter: 0; batch classifier loss: 0.465010\n",
      "epoch 10; iter: 0; batch classifier loss: 0.484621\n",
      "epoch 11; iter: 0; batch classifier loss: 0.407060\n",
      "epoch 12; iter: 0; batch classifier loss: 0.419592\n",
      "epoch 13; iter: 0; batch classifier loss: 0.441554\n",
      "epoch 14; iter: 0; batch classifier loss: 0.427963\n",
      "epoch 15; iter: 0; batch classifier loss: 0.367137\n",
      "epoch 16; iter: 0; batch classifier loss: 0.388691\n",
      "epoch 17; iter: 0; batch classifier loss: 0.348312\n",
      "epoch 18; iter: 0; batch classifier loss: 0.376493\n",
      "epoch 19; iter: 0; batch classifier loss: 0.388172\n",
      "epoch 20; iter: 0; batch classifier loss: 0.305386\n",
      "epoch 21; iter: 0; batch classifier loss: 0.392422\n",
      "epoch 22; iter: 0; batch classifier loss: 0.383665\n",
      "epoch 23; iter: 0; batch classifier loss: 0.367784\n",
      "epoch 24; iter: 0; batch classifier loss: 0.357423\n",
      "epoch 25; iter: 0; batch classifier loss: 0.374668\n",
      "epoch 26; iter: 0; batch classifier loss: 0.305816\n",
      "epoch 27; iter: 0; batch classifier loss: 0.360474\n",
      "epoch 28; iter: 0; batch classifier loss: 0.409648\n",
      "epoch 29; iter: 0; batch classifier loss: 0.380214\n",
      "epoch 30; iter: 0; batch classifier loss: 0.368314\n",
      "epoch 31; iter: 0; batch classifier loss: 0.443906\n",
      "epoch 32; iter: 0; batch classifier loss: 0.442721\n",
      "epoch 33; iter: 0; batch classifier loss: 0.380717\n",
      "epoch 34; iter: 0; batch classifier loss: 0.356869\n",
      "epoch 35; iter: 0; batch classifier loss: 0.416275\n",
      "epoch 36; iter: 0; batch classifier loss: 0.393434\n",
      "epoch 37; iter: 0; batch classifier loss: 0.477504\n",
      "epoch 38; iter: 0; batch classifier loss: 0.406865\n",
      "epoch 39; iter: 0; batch classifier loss: 0.362292\n",
      "epoch 40; iter: 0; batch classifier loss: 0.432714\n",
      "epoch 41; iter: 0; batch classifier loss: 0.436526\n",
      "epoch 42; iter: 0; batch classifier loss: 0.293109\n",
      "epoch 43; iter: 0; batch classifier loss: 0.344991\n",
      "epoch 44; iter: 0; batch classifier loss: 0.360832\n",
      "epoch 45; iter: 0; batch classifier loss: 0.391634\n",
      "epoch 46; iter: 0; batch classifier loss: 0.290609\n",
      "epoch 47; iter: 0; batch classifier loss: 0.436434\n",
      "epoch 48; iter: 0; batch classifier loss: 0.409100\n",
      "epoch 49; iter: 0; batch classifier loss: 0.296896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x7fc7f47b5730>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "plain_model.fit(fraud_dataset_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the plain model to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_nodebiasing_train = plain_model.predict(fraud_dataset_train)\n",
    "dataset_nodebiasing_test = plain_model.predict(fraud_dataset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for the dataset from plain model (without debiasing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.516495\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.482941\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.913978\n",
      "Test set: Balanced classification accuracy = 0.915278\n",
      "Test set: Disparate impact = 0.199024\n",
      "Test set: Equal opportunity difference = -0.136364\n",
      "Test set: Average odds difference = -0.109848\n",
      "Test set: Theil_index = 0.075116\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"#### Model - without debiasing - dataset metrics\"))\n",
    "metric_dataset_nodebiasing_train = BinaryLabelDatasetMetric(dataset_nodebiasing_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_nodebiasing_test = BinaryLabelDatasetMetric(dataset_nodebiasing_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
    "\n",
    "display(Markdown(\"#### Model - without debiasing - classification metrics\"))\n",
    "classified_metric_nodebiasing_test = ClassificationMetric(fraud_dataset_test, \n",
    "                                                 dataset_nodebiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply in-processing algorithm based on adversarial learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "sess = tf.compat.v1.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn parameters with debias set to True\n",
    "debiased_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='debiased_classifier',\n",
    "                          debias=True,\n",
    "                          sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.642110; batch adversarial loss: 0.888877\n",
      "epoch 1; iter: 0; batch classifier loss: 0.642764; batch adversarial loss: 0.840557\n",
      "epoch 2; iter: 0; batch classifier loss: 0.600318; batch adversarial loss: 0.875891\n",
      "epoch 3; iter: 0; batch classifier loss: 0.593848; batch adversarial loss: 0.884208\n",
      "epoch 4; iter: 0; batch classifier loss: 0.584626; batch adversarial loss: 0.869008\n",
      "epoch 5; iter: 0; batch classifier loss: 0.582606; batch adversarial loss: 0.861620\n",
      "epoch 6; iter: 0; batch classifier loss: 0.529098; batch adversarial loss: 0.882503\n",
      "epoch 7; iter: 0; batch classifier loss: 0.517912; batch adversarial loss: 0.871632\n",
      "epoch 8; iter: 0; batch classifier loss: 0.482781; batch adversarial loss: 0.864677\n",
      "epoch 9; iter: 0; batch classifier loss: 0.481300; batch adversarial loss: 0.905053\n",
      "epoch 10; iter: 0; batch classifier loss: 0.500655; batch adversarial loss: 0.859037\n",
      "epoch 11; iter: 0; batch classifier loss: 0.519192; batch adversarial loss: 0.851027\n",
      "epoch 12; iter: 0; batch classifier loss: 0.469297; batch adversarial loss: 0.840250\n",
      "epoch 13; iter: 0; batch classifier loss: 0.458501; batch adversarial loss: 0.857421\n",
      "epoch 14; iter: 0; batch classifier loss: 0.477040; batch adversarial loss: 0.889074\n",
      "epoch 15; iter: 0; batch classifier loss: 0.459039; batch adversarial loss: 0.836664\n",
      "epoch 16; iter: 0; batch classifier loss: 0.442559; batch adversarial loss: 0.822275\n",
      "epoch 17; iter: 0; batch classifier loss: 0.485992; batch adversarial loss: 0.835799\n",
      "epoch 18; iter: 0; batch classifier loss: 0.467369; batch adversarial loss: 0.820627\n",
      "epoch 19; iter: 0; batch classifier loss: 0.445349; batch adversarial loss: 0.819962\n",
      "epoch 20; iter: 0; batch classifier loss: 0.431345; batch adversarial loss: 0.811624\n",
      "epoch 21; iter: 0; batch classifier loss: 0.377695; batch adversarial loss: 0.816850\n",
      "epoch 22; iter: 0; batch classifier loss: 0.452407; batch adversarial loss: 0.806415\n",
      "epoch 23; iter: 0; batch classifier loss: 0.483381; batch adversarial loss: 0.814739\n",
      "epoch 24; iter: 0; batch classifier loss: 0.436174; batch adversarial loss: 0.802516\n",
      "epoch 25; iter: 0; batch classifier loss: 0.429898; batch adversarial loss: 0.790177\n",
      "epoch 26; iter: 0; batch classifier loss: 0.380951; batch adversarial loss: 0.811959\n",
      "epoch 27; iter: 0; batch classifier loss: 0.371850; batch adversarial loss: 0.800905\n",
      "epoch 28; iter: 0; batch classifier loss: 0.456689; batch adversarial loss: 0.785022\n",
      "epoch 29; iter: 0; batch classifier loss: 0.381553; batch adversarial loss: 0.781459\n",
      "epoch 30; iter: 0; batch classifier loss: 0.385127; batch adversarial loss: 0.777968\n",
      "epoch 31; iter: 0; batch classifier loss: 0.392857; batch adversarial loss: 0.766888\n",
      "epoch 32; iter: 0; batch classifier loss: 0.417324; batch adversarial loss: 0.777743\n",
      "epoch 33; iter: 0; batch classifier loss: 0.398890; batch adversarial loss: 0.766884\n",
      "epoch 34; iter: 0; batch classifier loss: 0.347161; batch adversarial loss: 0.765742\n",
      "epoch 35; iter: 0; batch classifier loss: 0.404484; batch adversarial loss: 0.735716\n",
      "epoch 36; iter: 0; batch classifier loss: 0.375715; batch adversarial loss: 0.750994\n",
      "epoch 37; iter: 0; batch classifier loss: 0.334297; batch adversarial loss: 0.743587\n",
      "epoch 38; iter: 0; batch classifier loss: 0.419963; batch adversarial loss: 0.747968\n",
      "epoch 39; iter: 0; batch classifier loss: 0.325557; batch adversarial loss: 0.768430\n",
      "epoch 40; iter: 0; batch classifier loss: 0.364017; batch adversarial loss: 0.743171\n",
      "epoch 41; iter: 0; batch classifier loss: 0.373241; batch adversarial loss: 0.719670\n",
      "epoch 42; iter: 0; batch classifier loss: 0.492977; batch adversarial loss: 0.708234\n",
      "epoch 43; iter: 0; batch classifier loss: 0.376906; batch adversarial loss: 0.729113\n",
      "epoch 44; iter: 0; batch classifier loss: 0.353953; batch adversarial loss: 0.724297\n",
      "epoch 45; iter: 0; batch classifier loss: 0.399055; batch adversarial loss: 0.703653\n",
      "epoch 46; iter: 0; batch classifier loss: 0.333622; batch adversarial loss: 0.724986\n",
      "epoch 47; iter: 0; batch classifier loss: 0.374487; batch adversarial loss: 0.703605\n",
      "epoch 48; iter: 0; batch classifier loss: 0.387070; batch adversarial loss: 0.688729\n",
      "epoch 49; iter: 0; batch classifier loss: 0.385473; batch adversarial loss: 0.707618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x7fc788493670>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debiased_model.fit(fraud_dataset_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the plain model to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_debiasing_train = debiased_model.predict(fraud_dataset_train)\n",
    "dataset_debiasing_test = debiased_model.predict(fraud_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.516495\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.482941\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.352715\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.321176\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.913978\n",
      "Test set: Balanced classification accuracy = 0.915278\n",
      "Test set: Disparate impact = 0.199024\n",
      "Test set: Equal opportunity difference = -0.136364\n",
      "Test set: Average odds difference = -0.109848\n",
      "Test set: Theil_index = 0.075116\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.838710\n",
      "Test set: Balanced classification accuracy = 0.843750\n",
      "Test set: Disparate impact = 0.272000\n",
      "Test set: Equal opportunity difference = 0.068182\n",
      "Test set: Average odds difference = 0.034091\n",
      "Test set: Theil_index = 0.175891\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Model - without debiasing - dataset metrics\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
    "\n",
    "# Metrics for the dataset from model with debiasing\n",
    "display(Markdown(\"#### Model - with debiasing - dataset metrics\"))\n",
    "metric_dataset_debiasing_train = BinaryLabelDatasetMetric(dataset_debiasing_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_debiasing_test = BinaryLabelDatasetMetric(dataset_debiasing_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_test.mean_difference())\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Model - without debiasing - classification metrics\"))\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Model - with debiasing - classification metrics\"))\n",
    "classified_metric_debiasing_test = ClassificationMetric(fraud_dataset_test, \n",
    "                                                 dataset_debiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_debiasing_test.accuracy())\n",
    "TPR = classified_metric_debiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_debiasing_test.true_negative_rate()\n",
    "bal_acc_debiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_debiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_debiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_debiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_debiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_debiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We have observed how to use AI 360 fairness toolkit to eliminate the bias during preprocessing & inprocessing stages of model building & development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
