{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "## This Notebook demonstrates how to reduce the bias during \"In-processing\" stage using AI 360 Fairness toolkit"}, {"metadata": {}, "cell_type": "markdown", "source": "### In-processing algorithm\nA bias mitigation algorithm that is applied to a model during its training."}, {"metadata": {}, "cell_type": "markdown", "source": "### Insert your credentials as credentials in the below cell\nClick on dropdown from Pipeline_LabelEncoder-0.1.zip under Data tab and select 'Credentials'"}, {"metadata": {}, "cell_type": "code", "source": "\n# @hidden_cell\n# The following code contains the credentials for a file in your IBM Cloud Object Storage.\n# You might want to remove those credentials before you share your notebook.\ncredentials = {\n    'IAM_SERVICE_ID': 'iam-ServiceId-d1dc205c-4852-439d-aaf7-025bfd1d1b3c',\n    'IBM_API_KEY_ID': 'dX403mHGXVg4BfGcsmJljAoDLJazlII_c0b_3F-3ZX4K',\n    'ENDPOINT': 'https://s3.private.us.cloud-object-storage.appdomain.cloud',\n    'IBM_AUTH_ENDPOINT': 'https://iam.cloud.ibm.com/oidc/token',\n    'BUCKET': 'aiethics-donotdelete-pr-8eprek5rk4yce3',\n    'FILE': 'Pipeline_LabelEncoder-0.1.zip'\n}\n", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from ibm_botocore.client import Config\nimport ibm_boto3\n\ncos = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id=credentials['IBM_API_KEY_ID'],\n    ibm_service_instance_id=credentials['IAM_SERVICE_ID'],\n    ibm_auth_endpoint=credentials['IBM_AUTH_ENDPOINT'],\n    config=Config(signature_version='oauth'),\n    endpoint_url=credentials['ENDPOINT'])", "execution_count": 5, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import os\nos.getcwd()", "execution_count": 6, "outputs": [{"output_type": "execute_result", "execution_count": 6, "data": {"text/plain": "'/home/wsuser/work'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "cos.download_file(Bucket=credentials['BUCKET'],Key='Pipeline_LabelEncoder-0.1.zip',Filename='/home/wsuser/work/Pipeline_LabelEncoder-0.1.zip')", "execution_count": 7, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "!ls", "execution_count": 8, "outputs": [{"output_type": "stream", "text": "Pipeline_LabelEncoder-0.1.zip\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "!pip install Pipeline_LabelEncoder-0.1.zip\n!pip install aif360", "execution_count": 9, "outputs": [{"output_type": "stream", "text": "Processing ./Pipeline_LabelEncoder-0.1.zip\nBuilding wheels for collected packages: Pipeline-LabelEncoder\n  Building wheel for Pipeline-LabelEncoder (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for Pipeline-LabelEncoder: filename=Pipeline_LabelEncoder-0.1-py3-none-any.whl size=2062 sha256=bbe6ef22a7571bfadd6ca44928b0aba33ec6f37eea3edcc551e47a4d5c371b5a\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/6b/4b/1e/43f3c8b97ffade4539a329b9eaa5755e4df16a248960947534\nSuccessfully built Pipeline-LabelEncoder\nInstalling collected packages: Pipeline-LabelEncoder\nSuccessfully installed Pipeline-LabelEncoder-0.1\nCollecting aif360\n  Downloading aif360-0.4.0-py3-none-any.whl (175 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 175 kB 25.2 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from aif360) (3.3.4)\nRequirement already satisfied: pandas>=0.24.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from aif360) (1.2.4)\nRequirement already satisfied: scikit-learn>=0.22.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from aif360) (0.23.2)\nRequirement already satisfied: scipy<1.6.0,>=1.2.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from aif360) (1.4.1)\nCollecting tempeh\n  Downloading tempeh-0.1.12-py3-none-any.whl (39 kB)\nRequirement already satisfied: numpy>=1.16 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from aif360) (1.19.2)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pandas>=0.24.0->aif360) (2.8.1)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pandas>=0.24.0->aif360) (2021.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->aif360) (1.15.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from scikit-learn>=0.22.1->aif360) (0.17.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from scikit-learn>=0.22.1->aif360) (2.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from matplotlib->aif360) (0.10.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from matplotlib->aif360) (1.3.1)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from matplotlib->aif360) (8.4.0)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from matplotlib->aif360) (2.4.7)\nRequirement already satisfied: pytest in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tempeh->aif360) (6.2.3)\nRequirement already satisfied: requests in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tempeh->aif360) (2.25.1)\nCollecting memory-profiler\n  Downloading memory_profiler-0.58.0.tar.gz (36 kB)\nCollecting shap\n  Downloading shap-0.40.0.tar.gz (371 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 371 kB 59.6 MB/s eta 0:00:01\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n\u001b[?25hCollecting psutil\n  Downloading psutil-5.8.0-cp38-cp38-manylinux2010_x86_64.whl (296 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 296 kB 53.5 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pytest->tempeh->aif360) (21.2.0)\nRequirement already satisfied: iniconfig in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pytest->tempeh->aif360) (1.1.1)\nRequirement already satisfied: packaging in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pytest->tempeh->aif360) (20.9)\nRequirement already satisfied: pluggy<1.0.0a1,>=0.12 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pytest->tempeh->aif360) (0.13.1)\nRequirement already satisfied: py>=1.8.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pytest->tempeh->aif360) (1.10.0)\nRequirement already satisfied: toml in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pytest->tempeh->aif360) (0.10.2)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests->tempeh->aif360) (2021.10.8)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests->tempeh->aif360) (2.8)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests->tempeh->aif360) (1.26.6)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests->tempeh->aif360) (3.0.4)\nRequirement already satisfied: tqdm>4.25.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from shap->tempeh->aif360) (4.59.0)\nCollecting numba\n  Downloading numba-0.54.1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3.3 MB 74.8 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: cloudpickle in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from shap->tempeh->aif360) (1.6.0)\nCollecting slicer==0.0.7\n  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\nCollecting packaging\n  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40 kB 17.2 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from numba->shap->tempeh->aif360) (52.0.0.post20211006)\nCollecting llvmlite<0.38,>=0.37.0rc1\n  Downloading llvmlite-0.37.0-cp38-cp38-manylinux2014_x86_64.whl (26.3 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 26.3 MB 25.8 MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: memory-profiler, shap\n  Building wheel for memory-profiler (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for memory-profiler: filename=memory_profiler-0.58.0-py3-none-any.whl size=30183 sha256=4e9e091033c16aa6956843349a25bb70e97edfd956c41a758aea7885d6c2d62a\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/6a/37/3e/d9e8ebaf73956a3ebd2ee41869444dbd2a702d7142bcf93c42\n  Building wheel for shap (PEP 517) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for shap: filename=shap-0.40.0-cp38-cp38-linux_x86_64.whl size=560093 sha256=1a19f0544f50ca9317dea3153a80a35c866ff920c0900f9ee135b56710384263\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/77/07/6b/ff54f2fdec86581ea5f6131ec0fd424bef58841d6684035114\nSuccessfully built memory-profiler shap\nInstalling collected packages: llvmlite, slicer, psutil, packaging, numba, shap, memory-profiler, tempeh, aif360\n  Attempting uninstall: packaging\n    Found existing installation: packaging 20.9\n    Uninstalling packaging-20.9:\n      Successfully uninstalled packaging-20.9\nSuccessfully installed aif360-0.4.0 llvmlite-0.37.0 memory-profiler-0.58.0 numba-0.54.1 packaging-21.3 psutil-5.8.0 shap-0.40.0 slicer-0.0.7 tempeh-0.1.12\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "import tensorflow as tf\ntf.__version__", "execution_count": 10, "outputs": [{"output_type": "execute_result", "execution_count": 10, "data": {"text/plain": "'2.4.3'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "!pip install 'tensorflow>=1.13.1'", "execution_count": 11, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: tensorflow>=1.13.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (2.4.3)\nRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=1.13.1) (3.11.2)\nRequirement already satisfied: six~=1.15.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=1.13.1) (1.15.0)\nRequirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=1.13.1) (3.3.0)\nRequirement already satisfied: numpy~=1.19.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=1.13.1) (1.19.2)\nRequirement already satisfied: termcolor~=1.1.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=1.13.1) (1.1.0)\nRequirement already satisfied: absl-py~=0.10 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=1.13.1) (0.10.0)\nRequirement already satisfied: h5py~=2.10.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=1.13.1) (2.10.0)\nRequirement already satisfied: typing-extensions~=3.7.4 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=1.13.1) (3.7.4.3)\nRequirement already satisfied: wheel~=0.35 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=1.13.1) (0.35.1)\nRequirement already satisfied: astunparse~=1.6.3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=1.13.1) (1.6.3)\nRequirement already satisfied: gast==0.3.3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=1.13.1) (0.3.3)\nRequirement already satisfied: tensorboard~=2.4 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=1.13.1) (2.4.1)\nRequirement already satisfied: google-pasta~=0.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=1.13.1) (0.2.0)\nRequirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=1.13.1) (1.1.2)\nRequirement already satisfied: wrapt~=1.12.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=1.13.1) (1.12.1)\nRequirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=1.13.1) (2.4.0)\nRequirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=1.13.1) (1.12)\nRequirement already satisfied: grpcio~=1.32.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow>=1.13.1) (1.32.0)\nRequirement already satisfied: setuptools in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from protobuf>=3.9.2->tensorflow>=1.13.1) (52.0.0.post20211006)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow>=1.13.1) (2.0.1)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow>=1.13.1) (3.1.1)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow>=1.13.1) (2.25.1)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow>=1.13.1) (1.6.0)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow>=1.13.1) (1.23.0)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow>=1.13.1) (0.4.4)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=1.13.1) (4.7.2)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=1.13.1) (4.2.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=1.13.1) (0.2.8)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=1.13.1) (1.3.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=1.13.1) (0.4.8)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=1.13.1) (1.26.6)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=1.13.1) (2021.10.8)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=1.13.1) (3.0.4)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=1.13.1) (2.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=1.13.1) (3.1.1)\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "%matplotlib inline\n# Load all necessary packages\nimport pandas as pd\nfrom aif360.datasets import BinaryLabelDataset\nfrom aif360.metrics import BinaryLabelDatasetMetric\nfrom aif360.metrics import ClassificationMetric\nfrom aif360.metrics.utils import compute_boolean_conditioning_vector\n\nfrom aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler, MaxAbsScaler\nfrom sklearn.metrics import accuracy_score\n\nfrom IPython.display import Markdown, display\nimport matplotlib.pyplot as plt", "execution_count": 13, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Insert the data as Pandas Dataframe and change the name from df_data_ to df"}, {"metadata": {}, "cell_type": "code", "source": "\nimport os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\n\nif os.environ.get('RUNTIME_ENV_LOCATION_TYPE') == 'external':\n    endpoint_ef3d35c2a4224ff082f537a81071807f = 'https://s3.us.cloud-object-storage.appdomain.cloud'\nelse:\n    endpoint_ef3d35c2a4224ff082f537a81071807f = 'https://s3.private.us.cloud-object-storage.appdomain.cloud'\n\nclient_ef3d35c2a4224ff082f537a81071807f = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='dX403mHGXVg4BfGcsmJljAoDLJazlII_c0b_3F-3ZX4K',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url=endpoint_ef3d35c2a4224ff082f537a81071807f)\n\nbody = client_ef3d35c2a4224ff082f537a81071807f.get_object(Bucket='aiethics-donotdelete-pr-8eprek5rk4yce3',Key='fraud_data.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf = pd.read_csv(body)\ndf.head()\n", "execution_count": 14, "outputs": [{"output_type": "execute_result", "execution_count": 14, "data": {"text/plain": "  Gender Married  Education Fraud_risk\n0   Male      No          1       Risk\n1   Male     Yes          1       Safe\n2   Male     Yes          1       Safe\n3   Male     Yes          0       Safe\n4   Male      No          1       Risk", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Gender</th>\n      <th>Married</th>\n      <th>Education</th>\n      <th>Fraud_risk</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Male</td>\n      <td>No</td>\n      <td>1</td>\n      <td>Risk</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>1</td>\n      <td>Safe</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>1</td>\n      <td>Safe</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>Safe</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Male</td>\n      <td>No</td>\n      <td>1</td>\n      <td>Risk</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "df.describe(include = 'all')", "execution_count": 15, "outputs": [{"output_type": "execute_result", "execution_count": 15, "data": {"text/plain": "       Gender Married   Education Fraud_risk\ncount     921     921  921.000000        921\nunique      2       2         NaN          2\ntop      Male      No         NaN       Safe\nfreq      703     501         NaN        562\nmean      NaN     NaN    0.730727        NaN\nstd       NaN     NaN    0.443823        NaN\nmin       NaN     NaN    0.000000        NaN\n25%       NaN     NaN    0.000000        NaN\n50%       NaN     NaN    1.000000        NaN\n75%       NaN     NaN    1.000000        NaN\nmax       NaN     NaN    1.000000        NaN", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Gender</th>\n      <th>Married</th>\n      <th>Education</th>\n      <th>Fraud_risk</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>921</td>\n      <td>921</td>\n      <td>921.000000</td>\n      <td>921</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>2</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>Male</td>\n      <td>No</td>\n      <td>NaN</td>\n      <td>Safe</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>703</td>\n      <td>501</td>\n      <td>NaN</td>\n      <td>562</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.730727</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.443823</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "privileged_groups = [{'Gender': 1}]\nunprivileged_groups = [{'Gender': 0}]\nfavorable_label = 1 \nunfavorable_label = 0", "execution_count": 16, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn import preprocessing\ncategorical_column = ['Gender', 'Married', 'Fraud_risk']\n\ndata_encoded = df.copy(deep=True)\n#Use Scikit-learn label encoding to encode character data\nlab_enc = preprocessing.LabelEncoder()\nfor col in categorical_column:\n        data_encoded[col] = lab_enc.fit_transform(df[col])\n        le_name_mapping = dict(zip(lab_enc.classes_, lab_enc.transform(lab_enc.classes_)))\n        print('Feature', col)\n        print('mapping', le_name_mapping)\n        \n\ndata_encoded.head()", "execution_count": 17, "outputs": [{"output_type": "stream", "text": "Feature Gender\nmapping {'Female': 0, 'Male': 1}\nFeature Married\nmapping {'No': 0, 'Yes': 1}\nFeature Fraud_risk\nmapping {'Risk': 0, 'Safe': 1}\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 17, "data": {"text/plain": "   Gender  Married  Education  Fraud_risk\n0       1        0          1           0\n1       1        1          1           1\n2       1        1          1           1\n3       1        1          0           1\n4       1        0          1           0", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Gender</th>\n      <th>Married</th>\n      <th>Education</th>\n      <th>Fraud_risk</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "from Pipeline_LabelEncoder.sklearn_label_encoder import PipelineLabelEncoder\npreprocessed_data = PipelineLabelEncoder(columns = ['Gender','Married', 'Fraud_risk']).fit_transform(data_encoded)\nprint('-------------------------')\n#print('validation data encoding')\n#validation_enc_data = PipelineLabelEncoder(columns = ['Gender','Married', 'Fraud_risk']).transform(validation_input_data)", "execution_count": 18, "outputs": [{"output_type": "stream", "text": "Inside fit transform\nFeature Gender\nmapping {0: 0, 1: 1}\nFeature Married\nmapping {0: 0, 1: 1}\nFeature Fraud_risk\nmapping {0: 0, 1: 1}\n-------------------------\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "#Create binary label dataset that can be used by bias mitigation algorithms\nfraud_dataset = BinaryLabelDataset(favorable_label=favorable_label,\n                                unfavorable_label=unfavorable_label,\n                                df=preprocessed_data,\n                                label_names=['Fraud_risk'],\n                                protected_attribute_names=['Gender', 'Married'],\n                                unprivileged_protected_attributes=unprivileged_groups)", "execution_count": 19, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "display(Markdown(\"#### Training Data Details\"))\nprint(\"shape of the training dataset\", fraud_dataset.features.shape)\nprint(\"Training data favorable label\", fraud_dataset.favorable_label)\nprint(\"Training data unfavorable label\", fraud_dataset.unfavorable_label)\nprint(\"Training data protected attribute\", fraud_dataset.protected_attribute_names)\nprint(\"Training data privileged protected attribute (1:Male and 0:Female)\", \n      fraud_dataset.privileged_protected_attributes)\nprint(\"Training data unprivileged protected attribute (1:Male and 0:Female)\",\n      fraud_dataset.unprivileged_protected_attributes)", "execution_count": 20, "outputs": [{"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.Markdown object>", "text/markdown": "#### Training Data Details"}, "metadata": {}}, {"output_type": "stream", "text": "shape of the training dataset (921, 3)\nTraining data favorable label 1.0\nTraining data unfavorable label 0.0\nTraining data protected attribute ['Gender', 'Married']\nTraining data privileged protected attribute (1:Male and 0:Female) [array([1.]), array([1.])]\nTraining data unprivileged protected attribute (1:Male and 0:Female) [array([0.]), array([0.])]\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "fraud_dataset_train, fraud_dataset_test = fraud_dataset.split([0.9], shuffle=True)", "execution_count": 21, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Metric for the original dataset\nmetric_orig_train = BinaryLabelDatasetMetric(fraud_dataset_train, \n                                             unprivileged_groups=unprivileged_groups,\n                                             privileged_groups=privileged_groups)\ndisplay(Markdown(\"#### Original training dataset\"))\nprint(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\nmetric_orig_test = BinaryLabelDatasetMetric(fraud_dataset_test, \n                                             unprivileged_groups=unprivileged_groups,\n                                             privileged_groups=privileged_groups)\nprint(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_test.mean_difference())", "execution_count": 22, "outputs": [{"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.Markdown object>", "text/markdown": "#### Original training dataset"}, "metadata": {}}, {"output_type": "stream", "text": "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.371556\nTest set: Difference in mean outcomes between unprivileged and privileged groups = -0.374822\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "min_max_scaler = MaxAbsScaler()\nfraud_dataset_train.features = min_max_scaler.fit_transform(fraud_dataset_train.features)\nfraud_dataset_test.features = min_max_scaler.transform(fraud_dataset_test.features)\nmetric_scaled_train = BinaryLabelDatasetMetric(fraud_dataset_train, \n                             unprivileged_groups=unprivileged_groups,\n                             privileged_groups=privileged_groups)\ndisplay(Markdown(\"#### Scaled dataset - Verify that the scaling does not affect the group label statistics\"))\nprint(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_train.mean_difference())\nmetric_scaled_test = BinaryLabelDatasetMetric(fraud_dataset_test, \n                             unprivileged_groups=unprivileged_groups,\n                             privileged_groups=privileged_groups)\nprint(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_test.mean_difference())\n", "execution_count": 23, "outputs": [{"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.Markdown object>", "text/markdown": "#### Scaled dataset - Verify that the scaling does not affect the group label statistics"}, "metadata": {}}, {"output_type": "stream", "text": "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.371556\nTest set: Difference in mean outcomes between unprivileged and privileged groups = -0.374822\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Build plan classifier without debiasing"}, {"metadata": {}, "cell_type": "code", "source": "# Load post-processing algorithm that equalizes the odds\n# Learn parameters with debias set to False\n# sess = tf.Session()\nsess = tf.compat.v1.Session()\n\nplain_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n                          unprivileged_groups = unprivileged_groups,\n                          scope_name='plain_classifier',\n                          debias=False,\n                          sess=sess)", "execution_count": 34, "outputs": []}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "tf.compat.v1.disable_eager_execution()\nplain_model.fit(fraud_dataset_train)\n", "execution_count": 37, "outputs": [{"output_type": "stream", "text": "WARNING:tensorflow:From /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\nepoch 0; iter: 0; batch classifier loss: 0.666113\nepoch 1; iter: 0; batch classifier loss: 0.645210\nepoch 2; iter: 0; batch classifier loss: 0.600706\nepoch 3; iter: 0; batch classifier loss: 0.576786\nepoch 4; iter: 0; batch classifier loss: 0.552515\nepoch 5; iter: 0; batch classifier loss: 0.519860\nepoch 6; iter: 0; batch classifier loss: 0.523782\nepoch 7; iter: 0; batch classifier loss: 0.535875\nepoch 8; iter: 0; batch classifier loss: 0.498684\nepoch 9; iter: 0; batch classifier loss: 0.493991\nepoch 10; iter: 0; batch classifier loss: 0.470357\nepoch 11; iter: 0; batch classifier loss: 0.470270\nepoch 12; iter: 0; batch classifier loss: 0.446249\nepoch 13; iter: 0; batch classifier loss: 0.433933\nepoch 14; iter: 0; batch classifier loss: 0.418300\nepoch 15; iter: 0; batch classifier loss: 0.410631\nepoch 16; iter: 0; batch classifier loss: 0.400611\nepoch 17; iter: 0; batch classifier loss: 0.369879\nepoch 18; iter: 0; batch classifier loss: 0.339287\nepoch 19; iter: 0; batch classifier loss: 0.402517\nepoch 20; iter: 0; batch classifier loss: 0.416226\nepoch 21; iter: 0; batch classifier loss: 0.355600\nepoch 22; iter: 0; batch classifier loss: 0.290477\nepoch 23; iter: 0; batch classifier loss: 0.361265\nepoch 24; iter: 0; batch classifier loss: 0.372463\nepoch 25; iter: 0; batch classifier loss: 0.346083\nepoch 26; iter: 0; batch classifier loss: 0.349973\nepoch 27; iter: 0; batch classifier loss: 0.442412\nepoch 28; iter: 0; batch classifier loss: 0.381899\nepoch 29; iter: 0; batch classifier loss: 0.316142\nepoch 30; iter: 0; batch classifier loss: 0.331423\nepoch 31; iter: 0; batch classifier loss: 0.343311\nepoch 32; iter: 0; batch classifier loss: 0.420190\nepoch 33; iter: 0; batch classifier loss: 0.431951\nepoch 34; iter: 0; batch classifier loss: 0.414820\nepoch 35; iter: 0; batch classifier loss: 0.350101\nepoch 36; iter: 0; batch classifier loss: 0.351667\nepoch 37; iter: 0; batch classifier loss: 0.376140\nepoch 38; iter: 0; batch classifier loss: 0.300753\nepoch 39; iter: 0; batch classifier loss: 0.385323\nepoch 40; iter: 0; batch classifier loss: 0.313223\nepoch 41; iter: 0; batch classifier loss: 0.384614\nepoch 42; iter: 0; batch classifier loss: 0.364010\nepoch 43; iter: 0; batch classifier loss: 0.361881\nepoch 44; iter: 0; batch classifier loss: 0.326307\nepoch 45; iter: 0; batch classifier loss: 0.314854\nepoch 46; iter: 0; batch classifier loss: 0.400324\nepoch 47; iter: 0; batch classifier loss: 0.440709\nepoch 48; iter: 0; batch classifier loss: 0.480336\nepoch 49; iter: 0; batch classifier loss: 0.378217\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 37, "data": {"text/plain": "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x7f83ce926b20>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Apply the plain model to test data"}, {"metadata": {}, "cell_type": "code", "source": "dataset_nodebiasing_train = plain_model.predict(fraud_dataset_train)\ndataset_nodebiasing_test = plain_model.predict(fraud_dataset_test)", "execution_count": 38, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Metrics for the dataset from plain model (without debiasing)"}, {"metadata": {}, "cell_type": "code", "source": "display(Markdown(\"#### Model - without debiasing - dataset metrics\"))\nmetric_dataset_nodebiasing_train = BinaryLabelDatasetMetric(dataset_nodebiasing_train, \n                                             unprivileged_groups=unprivileged_groups,\n                                             privileged_groups=privileged_groups)\n\nprint(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n\nmetric_dataset_nodebiasing_test = BinaryLabelDatasetMetric(dataset_nodebiasing_test, \n                                             unprivileged_groups=unprivileged_groups,\n                                             privileged_groups=privileged_groups)\n\nprint(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n\ndisplay(Markdown(\"#### Model - without debiasing - classification metrics\"))\nclassified_metric_nodebiasing_test = ClassificationMetric(fraud_dataset_test, \n                                                 dataset_nodebiasing_test,\n                                                 unprivileged_groups=unprivileged_groups,\n                                                 privileged_groups=privileged_groups)\nprint(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\nTPR = classified_metric_nodebiasing_test.true_positive_rate()\nTNR = classified_metric_nodebiasing_test.true_negative_rate()\nbal_acc_nodebiasing_test = 0.5*(TPR+TNR)\nprint(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\nprint(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\nprint(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\nprint(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\nprint(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())", "execution_count": 39, "outputs": [{"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.Markdown object>", "text/markdown": "#### Model - without debiasing - dataset metrics"}, "metadata": {}}, {"output_type": "stream", "text": "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.513849\nTest set: Difference in mean outcomes between unprivileged and privileged groups = -0.507112\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.Markdown object>", "text/markdown": "#### Model - without debiasing - classification metrics"}, "metadata": {}}, {"output_type": "stream", "text": "Test set: Classification accuracy = 0.827957\nTest set: Balanced classification accuracy = 0.806452\nTest set: Disparate impact = 0.341644\nTest set: Equal opportunity difference = -0.176623\nTest set: Average odds difference = -0.298838\nTest set: Theil_index = 0.119251\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Apply in-processing algorithm based on adversarial learning"}, {"metadata": {}, "cell_type": "code", "source": "sess.close()\ntf.compat.v1.reset_default_graph()\nsess = tf.compat.v1.Session()", "execution_count": 42, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Learn parameters with debias set to True\ndebiased_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n                          unprivileged_groups = unprivileged_groups,\n                          scope_name='debiased_classifier',\n                          debias=True,\n                          sess=sess)", "execution_count": 43, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "debiased_model.fit(fraud_dataset_train)", "execution_count": 44, "outputs": [{"output_type": "stream", "text": "epoch 0; iter: 0; batch classifier loss: 0.720624; batch adversarial loss: 0.825836\nepoch 1; iter: 0; batch classifier loss: 0.681766; batch adversarial loss: 0.793567\nepoch 2; iter: 0; batch classifier loss: 0.698799; batch adversarial loss: 0.831468\nepoch 3; iter: 0; batch classifier loss: 0.643142; batch adversarial loss: 0.803706\nepoch 4; iter: 0; batch classifier loss: 0.639541; batch adversarial loss: 0.827873\nepoch 5; iter: 0; batch classifier loss: 0.632800; batch adversarial loss: 0.815942\nepoch 6; iter: 0; batch classifier loss: 0.581710; batch adversarial loss: 0.859766\nepoch 7; iter: 0; batch classifier loss: 0.603391; batch adversarial loss: 0.819742\nepoch 8; iter: 0; batch classifier loss: 0.557663; batch adversarial loss: 0.853227\nepoch 9; iter: 0; batch classifier loss: 0.574924; batch adversarial loss: 0.841624\nepoch 10; iter: 0; batch classifier loss: 0.512254; batch adversarial loss: 0.847106\nepoch 11; iter: 0; batch classifier loss: 0.518143; batch adversarial loss: 0.828914\nepoch 12; iter: 0; batch classifier loss: 0.491260; batch adversarial loss: 0.829677\nepoch 13; iter: 0; batch classifier loss: 0.490572; batch adversarial loss: 0.840950\nepoch 14; iter: 0; batch classifier loss: 0.483904; batch adversarial loss: 0.839075\nepoch 15; iter: 0; batch classifier loss: 0.490017; batch adversarial loss: 0.814533\nepoch 16; iter: 0; batch classifier loss: 0.469209; batch adversarial loss: 0.809723\nepoch 17; iter: 0; batch classifier loss: 0.465881; batch adversarial loss: 0.832302\nepoch 18; iter: 0; batch classifier loss: 0.448633; batch adversarial loss: 0.834733\nepoch 19; iter: 0; batch classifier loss: 0.448222; batch adversarial loss: 0.831150\nepoch 20; iter: 0; batch classifier loss: 0.446306; batch adversarial loss: 0.814186\nepoch 21; iter: 0; batch classifier loss: 0.432568; batch adversarial loss: 0.789774\nepoch 22; iter: 0; batch classifier loss: 0.423098; batch adversarial loss: 0.794449\nepoch 23; iter: 0; batch classifier loss: 0.379738; batch adversarial loss: 0.792296\nepoch 24; iter: 0; batch classifier loss: 0.409447; batch adversarial loss: 0.810721\nepoch 25; iter: 0; batch classifier loss: 0.420159; batch adversarial loss: 0.804706\nepoch 26; iter: 0; batch classifier loss: 0.392822; batch adversarial loss: 0.793357\nepoch 27; iter: 0; batch classifier loss: 0.476644; batch adversarial loss: 0.748373\nepoch 28; iter: 0; batch classifier loss: 0.356491; batch adversarial loss: 0.794399\nepoch 29; iter: 0; batch classifier loss: 0.458830; batch adversarial loss: 0.759337\nepoch 30; iter: 0; batch classifier loss: 0.421427; batch adversarial loss: 0.753365\nepoch 31; iter: 0; batch classifier loss: 0.455401; batch adversarial loss: 0.759755\nepoch 32; iter: 0; batch classifier loss: 0.452900; batch adversarial loss: 0.745947\nepoch 33; iter: 0; batch classifier loss: 0.375509; batch adversarial loss: 0.773660\nepoch 34; iter: 0; batch classifier loss: 0.394105; batch adversarial loss: 0.741767\nepoch 35; iter: 0; batch classifier loss: 0.504347; batch adversarial loss: 0.739079\nepoch 36; iter: 0; batch classifier loss: 0.473610; batch adversarial loss: 0.731684\nepoch 37; iter: 0; batch classifier loss: 0.409534; batch adversarial loss: 0.755917\nepoch 38; iter: 0; batch classifier loss: 0.400487; batch adversarial loss: 0.720281\nepoch 39; iter: 0; batch classifier loss: 0.422169; batch adversarial loss: 0.731629\nepoch 40; iter: 0; batch classifier loss: 0.485438; batch adversarial loss: 0.714886\nepoch 41; iter: 0; batch classifier loss: 0.360194; batch adversarial loss: 0.714097\nepoch 42; iter: 0; batch classifier loss: 0.332482; batch adversarial loss: 0.718490\nepoch 43; iter: 0; batch classifier loss: 0.376526; batch adversarial loss: 0.713327\nepoch 44; iter: 0; batch classifier loss: 0.365612; batch adversarial loss: 0.702300\nepoch 45; iter: 0; batch classifier loss: 0.454406; batch adversarial loss: 0.711404\nepoch 46; iter: 0; batch classifier loss: 0.466487; batch adversarial loss: 0.701236\nepoch 47; iter: 0; batch classifier loss: 0.384634; batch adversarial loss: 0.717136\nepoch 48; iter: 0; batch classifier loss: 0.378270; batch adversarial loss: 0.700205\nepoch 49; iter: 0; batch classifier loss: 0.385257; batch adversarial loss: 0.689785\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 44, "data": {"text/plain": "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x7f83bc79a2e0>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Apply the plain model to test data"}, {"metadata": {}, "cell_type": "code", "source": "dataset_debiasing_train = debiased_model.predict(fraud_dataset_train)\ndataset_debiasing_test = debiased_model.predict(fraud_dataset_test)", "execution_count": 45, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Metrics for the dataset from plain model (without debiasing)\ndisplay(Markdown(\"#### Model - without debiasing - dataset metrics\"))\nprint(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\nprint(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n\n# Metrics for the dataset from model with debiasing\ndisplay(Markdown(\"#### Model - with debiasing - dataset metrics\"))\nmetric_dataset_debiasing_train = BinaryLabelDatasetMetric(dataset_debiasing_train, \n                                             unprivileged_groups=unprivileged_groups,\n                                             privileged_groups=privileged_groups)\n\nprint(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_train.mean_difference())\n\nmetric_dataset_debiasing_test = BinaryLabelDatasetMetric(dataset_debiasing_test, \n                                             unprivileged_groups=unprivileged_groups,\n                                             privileged_groups=privileged_groups)\n\nprint(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_test.mean_difference())\n\n\n\ndisplay(Markdown(\"#### Model - without debiasing - classification metrics\"))\nprint(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\nTPR = classified_metric_nodebiasing_test.true_positive_rate()\nTNR = classified_metric_nodebiasing_test.true_negative_rate()\nbal_acc_nodebiasing_test = 0.5*(TPR+TNR)\nprint(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\nprint(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\nprint(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\nprint(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\nprint(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())\n\n\n\ndisplay(Markdown(\"#### Model - with debiasing - classification metrics\"))\nclassified_metric_debiasing_test = ClassificationMetric(fraud_dataset_test, \n                                                 dataset_debiasing_test,\n                                                 unprivileged_groups=unprivileged_groups,\n                                                 privileged_groups=privileged_groups)\nprint(\"Test set: Classification accuracy = %f\" % classified_metric_debiasing_test.accuracy())\nTPR = classified_metric_debiasing_test.true_positive_rate()\nTNR = classified_metric_debiasing_test.true_negative_rate()\nbal_acc_debiasing_test = 0.5*(TPR+TNR)\nprint(\"Test set: Balanced classification accuracy = %f\" % bal_acc_debiasing_test)\nprint(\"Test set: Disparate impact = %f\" % classified_metric_debiasing_test.disparate_impact())\nprint(\"Test set: Equal opportunity difference = %f\" % classified_metric_debiasing_test.equal_opportunity_difference())\nprint(\"Test set: Average odds difference = %f\" % classified_metric_debiasing_test.average_odds_difference())\nprint(\"Test set: Theil_index = %f\" % classified_metric_debiasing_test.theil_index())", "execution_count": 46, "outputs": [{"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.Markdown object>", "text/markdown": "#### Model - without debiasing - dataset metrics"}, "metadata": {}}, {"output_type": "stream", "text": "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.513849\nTest set: Difference in mean outcomes between unprivileged and privileged groups = -0.507112\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.Markdown object>", "text/markdown": "#### Model - with debiasing - dataset metrics"}, "metadata": {}}, {"output_type": "stream", "text": "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.222623\nTest set: Difference in mean outcomes between unprivileged and privileged groups = -0.265292\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.Markdown object>", "text/markdown": "#### Model - without debiasing - classification metrics"}, "metadata": {}}, {"output_type": "stream", "text": "Test set: Classification accuracy = 0.827957\nTest set: Balanced classification accuracy = 0.806452\nTest set: Disparate impact = 0.341644\nTest set: Equal opportunity difference = -0.176623\nTest set: Average odds difference = -0.298838\nTest set: Theil_index = 0.119251\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.Markdown object>", "text/markdown": "#### Model - with debiasing - classification metrics"}, "metadata": {}}, {"output_type": "stream", "text": "Test set: Classification accuracy = 0.817204\nTest set: Balanced classification accuracy = 0.846774\nTest set: Disparate impact = 0.543452\nTest set: Equal opportunity difference = -0.049351\nTest set: Average odds difference = -0.009324\nTest set: Theil_index = 0.185230\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## We have observed how to use AI 360 fairness toolkit to eliminate the bias during preprocessing & inprocessing stages of model building & development."}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.8", "language": "python"}, "language_info": {"name": "python", "version": "3.8.12", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}